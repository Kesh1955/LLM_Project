{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM As Judge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from src.LLM_as_judge.answer import V1_EXPLANATION_ANSWER_PROMPT\n",
    "\n",
    "train_df = add_llm_explanation_column(\n",
    "    df= train_df,\n",
    "    system_prompts_dict=V1_ANSWER_SYSTEM_PROMPT,  # your prompt\n",
    "    model_name=\"gpt-4\",\n",
    "    gold_col=\"gold_answer\",\n",
    "    pred_col=\"model_answer\",\n",
    "    new_col_name=\"answer_explanation\"\n",
    ")\n",
    "\n",
    "train_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic way to add columns and prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "system_prompts_cot = {\n",
    "    \"system_prompt\": (\n",
    "        \"You are a helpful assistant.\\n\"\n",
    "        \"Please think step-by-step to find the correct answer.\\n\"\n",
    "        \"Only provide the answer as a float, with no symbols exept for - when required.\"\n",
    "        \"Then provide only the final answer.\\n\\n\"\n",
    "        \"=== PRE TEXT ===\\n{pre_text}\\n\\n\"\n",
    "        \"=== POST TEXT ===\\n{post_text}\\n\\n\"\n",
    "        \"=== TABLE ===\\n{table}\\n\\n\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "def construct_main_messages(record: dict, system_prompts: dict) -> list:\n",
    "    \"\"\"\n",
    "    Builds the final messages by looking up a prompt in system_prompts[\"system_prompt\"],\n",
    "    then formatting placeholders {pre_text}, {post_text}, and {table} with data from record.\n",
    "    \"\"\"\n",
    "    system_prompt_template = system_prompts[\"system_prompt\"]\n",
    "    \n",
    "    system_message_content = system_prompt_template.format(\n",
    "        pre_text=record.get(\"pre_text\", \"\"),\n",
    "        post_text=record.get(\"post_text\", \"\"),\n",
    "        table=record.get(\"table\", \"\")  # always use record[\"table\"]\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message_content},\n",
    "        {\"role\": \"user\", \"content\": record.get(\"question\", \"\")}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def process_records(records, system_prompts, model_name, prompt_style):\n",
    "    \"\"\"\n",
    "    For each record, calls OpenAI and returns a DataFrame with [id, question, gold_answer, model_answer, model, prompt_style].\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for r in records:\n",
    "        messages = construct_main_messages(r, system_prompts)\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=messages\n",
    "            )\n",
    "            model_answer = response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            model_answer = f\"Error: {e}\"\n",
    "\n",
    "        results.append({\n",
    "            \"id\": r[\"id\"],\n",
    "            \"question\": r[\"question\"],\n",
    "            \"gold_answer\": r[\"gold_answer\"],\n",
    "            \"table\": r[\"table\"],\n",
    "            \"model_answer\": model_answer,\n",
    "            \"model\": model_name,\n",
    "            \"prompt_style\": prompt_style,\n",
    "            \"prompt\": system_prompts,\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.models import gpt_4o_mini\n",
    "\n",
    "df_run_cot = process_records(\n",
    "    records=train_data[:2],\n",
    "    system_prompts=V1_ANSWER_SYSTEM_PROMPT,\n",
    "    model_name= gpt_4o_mini,\n",
    "    prompt_style=\"CoT\"\n",
    ")\n",
    "\n",
    "df_run_cot.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using o1 - The prompt structure is different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": f\"\"\"{Conversion_prompt}\n",
    "\n",
    "#             QUESTION:\n",
    "#             {question}\n",
    "#             \"\"\"\n",
    "\n",
    "#             # Insert json relevant data somewhere, ask the question to help it answer the questions\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     # 6. Call the OpenAI ChatCompletion endpoint\n",
    "#     try:\n",
    "#         response = openai.chat.completions.create(\n",
    "#             model='o1-preview',\n",
    "#             messages=messages\n",
    "\n",
    "#         )\n",
    "#         model_answer = response.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         model_answer = f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Notes and questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final output - What will you show and send to Tomorro?\n",
    "\n",
    "\n",
    "# Key Q's \n",
    "\n",
    "\n",
    "# 1.  How will you run the best prompt on the Dev set (also will reduce to like ~100 samples as well given costs)\n",
    "# 1. How will you improve model performance? (criteria:systematic, repeatable, automatable???) \n",
    "# 1. How will the evals be presented? \n",
    "# 2. How will you track model and prompts?\n",
    "\n",
    "\n",
    "### In notebook\n",
    "1. Evals on 'accuracy' via exact-match with basic prompt and 4o.\n",
    "2. Evals on program execution via exact match and specified criteria with basic prompt and 4o.\n",
    "3. Improvements made via prompt-engineering (i) CoT & (ii) ReAct using 4o based on insights gathered in first experiments.\n",
    "4. Improvements made via reasoning tooling to determine what differences were possible using reasoning models.\n",
    "5. Fine-tunning to dertemine wheather further improvements were possible.\n",
    "\n",
    "\n",
    "### Submission \n",
    "- A link to a repo with the current code structure and accompanying info in README.md \n",
    "\n",
    "\n",
    "\n",
    "### Must-have's:\n",
    "1. All items in notebook\n",
    "2. Submission\n",
    "\n",
    "\n",
    "\n",
    "### Should\n",
    "1. ...\n",
    "\n",
    "\n",
    "### Could \n",
    "1. .. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of using all 3 prompt variants:\n",
    "prompt_variants = {\n",
    "    \"CoT\": V1_COT_PROGRAM_SYSTEM_PROMPT ,\n",
    "    \"ReAct\": v1_REACT_PROGRAM_SYSTEM_PROMPT\n",
    "}\n",
    "\n",
    "all_dfs = []\n",
    "for style_name, prompt_dict in prompt_variants.items():\n",
    "    # e.g. \"CoT\" => \"cot_answer\", \"ReAct\" => \"react_answer\"\n",
    "    answer_col = f\"{style_name.lower()}_answer\"\n",
    "\n",
    "    df_run = process_records(\n",
    "        records=train_data[:2],\n",
    "        system_prompts=prompt_dict,\n",
    "        model_name=gpt_4o_mini,\n",
    "        prompt_style=style_name,\n",
    "        answer_col_name=answer_col\n",
    "    )\n",
    "    # store only the ID + newly created answer column + any other needed columns\n",
    "    keep_cols = [\"id\", answer_col]\n",
    "    # We can keep or remove columns depending on how you want to merge\n",
    "    all_dfs.append(df_run[keep_cols + [\"question\", \"gold_answer\"]]) \n",
    "    \n",
    "    all_dfs[0]\n",
    "\n",
    "exact_match_score(master_df, \"numeric_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add\",\n",
    "            \"description\": \"Add two numbers together.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"The first number.\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"The second number.\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"subtract\",\n",
    "            \"description\": \"Subtract one number from another.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"The first number.\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"The second number.\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"multiply\",\n",
    "            \"description\": \"Multiply two numbers together.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"The first number.\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"The second number.\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"divide\",\n",
    "            \"description\": \"Divide one number by another.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"The numerator.\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"The denominator (cannot be zero).\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "V1_EXPLANATION_ANSWER_PROMPT = {\n",
    "    \"system_prompt\": (\n",
    "        \"You are an explanation expert focusing on numeric discrepancies.\\n\"\n",
    "        \"You have a gold (correct) numeric answer and a predicted numeric answer.\\n\"\n",
    "        \"Your task is to compare these two answers and provide a short, clear explanation of why they might differ.\\n\"\n",
    "        \"If they match, simply confirm there is no discrepancy.\\n\\n\"\n",
    "\n",
    "        \"=== PRE TEXT ===\\n{pre_text}\\n\\n\"\n",
    "        \"=== POST TEXT ===\\n{post_text}\\n\\n\"\n",
    "        \"=== HTML TABLE ===\\n{table}\\n\\n\"\n",
    "\n",
    "        \"Consider potential rounding, unit differences, or other reasons.\\n\"\n",
    "        \"Return only a brief explanation in plain text, no chain-of-thought.\\n\"\n",
    "        \"End of instructions.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "system_template = V1_EXPLANATION_ANSWER_PROMPT [\"system_prompt\"]\n",
    "system_msg = system_template.format(\n",
    "            pre_text=row.get(\"pre_text\",\"\"),\n",
    "            post_text=row.get(\"post_text\",\"\"),\n",
    "            table=row.get(\"html_table\",\"\")\n",
    "        )\n",
    "\n",
    "    {\"role\": \"user\", \"content\": q}\n",
    "  ],\n",
    "  logprobs=True,\n",
    "  tools=tools\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "print(completion.model)\n",
    "print(completion.usage.completion_tokens_details.accepted_prediction_tokens)\n",
    "print(completion.choices[0].logprobs)\n",
    "\n",
    "\n",
    "\n",
    "train_data[1]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\"Use the provided functions to answer questions.\"\n",
    "\"Your task is to create a mathematic program to answer the question given the information pre_text, post_text and html_table.\\n\"\n",
    "\"If they match, simply confirm there is no discrepancy.\\n\\n\"\n",
    " \"where each new operation references the previous result with #0, #1, etc.\\n\\n\"\n",
    " For example Program: subtract(7525,7344), divide(#0,7344)n\\n\"\n",
    " \"you may have to use more than one tool\"\n",
    " Also response with your final answer in a a float point\n",
    "'pre_text': 'fortron industries llc .fortron is a leading global producer of pps , sold under the fortron ae brand , which is used in a wide variety of automotive and other applications , especially those requiring heat and/or chemical resistance .fortron\\'s facility is located in wilmington , north carolina .this venture combines the sales , marketing , distribution , compounding and manufacturing expertise of celanese with the pps polymer technology expertise of kureha america inc .cellulose derivatives strategic ventures .our cellulose derivatives ventures generally fund their operations using operating cash flow and pay dividends based on each ventures\\' performance in the preceding year .in 2014 , 2013 and 2012 , we received cash dividends of $ 115 million , $ 92 million and $ 83 million , respectively .although our ownership interest in each of our cellulose derivatives ventures exceeds 20% ( 20 % ) , we account for these investments using the cost method of accounting because we determined that we cannot exercise significant influence over these entities due to local government investment in and influence over these entities , limitations on our involvement in the day-to-day operations and the present inability of the entities to provide timely financial information prepared in accordance with generally accepted accounting principles in the united states of america ( \"us gaap\" ) .2022 other equity method investments infraservs .we hold indirect ownership interests in several german infraserv groups that own and develop industrial parks and provide on-site general and administrative support to tenants .our ownership interest in the equity investments in infraserv affiliates are as follows : as of december 31 , 2014 ( in percentages ) .'\n",
    "'post_text': 'research and development our businesses are innovation-oriented and conduct research and development activities to develop new , and optimize existing , production technologies , as well as to develop commercially viable new products and applications .research and development expense was $ 86 million , $ 85 million and $ 104 million for the years ended december 31 , 2014 , 2013 and 2012 , respectively .we consider the amounts spent during each of the last three fiscal years on research and development activities to be sufficient to execute our current strategic initiatives .intellectual property we attach importance to protecting our intellectual property , including safeguarding our confidential information and through our patents , trademarks and copyrights , in order to preserve our investment in research and development , manufacturing and marketing .patents may cover processes , equipment , products , intermediate products and product uses .we also seek to register trademarks as a means of protecting the brand names of our company and products .patents .in most industrial countries , patent protection exists for new substances and formulations , as well as for certain unique applications and production processes .however , we do business in regions of the world where intellectual property protection may be limited and difficult to enforce .confidential information .we maintain stringent information security policies and procedures wherever we do business .such information security policies and procedures include data encryption , controls over the disclosure and safekeeping of confidential information and trade secrets , as well as employee awareness training .trademarks .aoplus ae , aoplus ae2 , aoplus ae3 , ateva ae , avicor ae , britecoat ae , celanese ae , celanex ae , celcon ae , celfx 2122 , celstran ae , celvolit ae , clarifoil ae , duroset ae , ecovae ae , factor ae , fortron ae , gur ae , hostaform ae , impet ae , mowilith ae , nutrinova ae , qorus 2122 , riteflex ae , sunett ae , tcx 2122 , thermx ae , tufcor ae , vantage ae , vantageplus 2122 , vantage ae2 , vectra ae , vinamul ae , vitaldose ae , zenite ae and certain other branded products and services named in this document are registered or reserved trademarks or service marks owned or licensed by celanese .the foregoing is not intended to be an exhaustive or comprehensive list of all registered or reserved trademarks and service marks owned or licensed by celanese .fortron ae is a registered trademark of fortron industries llc. .',\"\n",
    "'html_table': '<table>\\n  <thead>\\n    <tr>\\n      <th></th>\\n      <th>as of december 31 2014 ( in percentages )</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr><td>infraserv gmbh & co . gendorf kg</td><td>39</td></tr>\\n    <tr><td>infraserv gmbh & co . hoechst kg</td><td>32</td></tr>\\n    <tr><td>infraserv gmbh & co . knapsack kg</td><td>27</td></tr>\\n  </tbody>\\n</table>',\n",
    "\"\"\"\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "q = 'what was the percentage growth of the cash dividends from 2012 to 2014?'\n",
    "p =  'subtract(115, 83), divide(#0, 83)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "thread = openai.beta.threads.create()\n",
    "completion = openai.beta.assistants.create(\n",
    "  model=\"gpt-4o\",\n",
    "  instructions= prompt,\n",
    "  tools=tools\n",
    ")\n",
    "\n",
    "# print(completion.choices[0].message)\n",
    "# print(completion.model)\n",
    "# print(completion.usage.completion_tokens_details.accepted_prediction_tokens)\n",
    "# print(completion.choices[0].logprobs)\n",
    "thread = openai.beta.threads.create()\n",
    "message = openai.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=q,\n",
    ")\n",
    "\n",
    "print(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
